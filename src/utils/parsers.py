import matplotlib.pyplot as plt
import numpy as np
import sklearn
import pandas as pd
import os
import sys
from sklearn.cluster import DBSCAN
from sklearn import metrics
from sklearn.datasets import make_blobs
import glob
from sklearn.preprocessing import StandardScaler
sys.path.append(".")
from . import ransac_fit
from shutil import copyfile
import math

#convert coodinate files generated by any EMAN picking programs(ie. e2helixboxer.py) into coordinate files supported by topaz
def parse_EMAN_coordinates(path_to_EMAN, path_to_topaz):
    EMAN_files = os.listdir(path_to_EMAN)
    EMAN_files = [x for x in EMAN_files if ".txt" in x]
    #some special cases

    t = open(path_to_topaz+"/particle_coords.txt", "w")

    t.write("image_name\tx_coord\ty_coord\n")
    for file in EMAN_files:
        ofile = file.replace(".txt", "")

        print(ofile)

        f = open(path_to_EMAN + "/" + file, "r")
        for i in range(6):
            f.readline()
        for line in f:
            if (not ("#helix: " in line)):
                nums = line.split("\t")
                nums = [float(x) for x in nums]

                nfile = file.replace(".txt", "")
                t.write(nfile + "\t" + str(int(nums[0])) + "\t" + str(int(nums[1])) + "\n")


#convert coordinate files generated by the topaz program into coordinate files supported by filament mode
def parse_topaz_coordinates(path_to_topaz, path_to_helix):
    f = open(path_to_topaz, "r")
    f.readline()  # skip one line
    o = None

    current_title = ""

    for x in f:
        line = x.split("\t")
        if line[0] != current_title:
            current_title = line[0]
            o = open(os.path.join(path_to_helix,line[0]) + ".txt", "w")

            o.write("x_coord\ty_coord\tscore\n")
            o.write(line[1] + "\t" + line[2] + "\t" + line[3])
        else:
            o.write(line[1] + "\t" + line[2] + "\t" + line[3])
    return 1

#input: a directory containing input coordinate files generated by parse_topaz_coordinates
#returns an dictionary of coordinates whose elements are in the following format:
#       "file_name": x_coords(np array) y_coords(np array)
def parse_helix_coordinates(path, threshold=-2.5):
    #parse each file
    file_library = {}
    threshold_score = threshold

    for file in os.listdir(path)[0:]:
        try:
            df = pd.read_csv(os.path.join(path,file), sep="\t")
            df = df.drop(df[df.score<threshold_score].index)
            x = df["x_coord"].to_numpy()
            y = df["y_coord"].to_numpy()
            tup = (x,y)
            file_library.update({file: tup})
        except AttributeError:
            #if an input file did not satisfy requirements
            continue

    return file_library

def star_to_helix(filename, pixel_size, output_path, default_threshold, keep_path = False):
    file = open(filename, "r")
    Lines = file.readlines()
    
    index_for_name = Lines[32].index

    mrc_name = os.path.basename(Lines[32].split()[0])

    print(Lines[32])
    o =  open(os.path.join(output_path, mrc_name), "w")

    for i in range(32, len(Lines)):
        #check mrc title
        
        parts = Lines[i].split()
        if (mrc_name != os.path.basename(parts[0])):
            o.close()
            mrc_name = os.path.basename(parts[0])
            o = open(os.path.join(output_path, mrc_name), "w")


        x = float(parts[2])-float(parts[5])/pixel_size
        y = float(parts[3])-float(parts[6])/pixel_size

        if not keep_path:
            o.write(os.path.basename(parts[1])+"\t"+str(x)+"\t"+str(y)+"\t"+str(default_threshold)+"\n")
        else:
            o.write(parts[1] + "\t" + str(x) + "\t" + str(y) + "\t" + str(default_threshold) + "\n")



def calculatepsi(x, y):
    """Calculate the psi from the tangent"""
    xd = np.diff(x)
    yd = np.diff(y)
    psirad = np.arctan2(yd,xd)*-1
    psi = np.array(psirad)*180/math.pi
    psi = np.hstack([psi, [psi.max()]])
    return psi
    #print(psi)

def get_cumulative_dist(x,y):
    XY = np.concatenate((x[:, np.newaxis], y[:, np.newaxis]), axis = 1)
    diff = np.diff(XY, axis=0)
    ss = np.power(diff, 2).sum(axis=1)
    
    res = np.sqrt(ss)
    cum_sum = np.cumsum(res, axis = 0)
    return np.insert(cum_sum, 0, 0, axis = 0)
    
def write_line(np_line):
    lst = list(np_line)
    lst = (str(x) for x in lst)
    return (" ".join(lst))+"\n"

def box_to_star(box_file, output_name, template_file_path, destination_path):
    star_file_string = open(template_file_path, "r")
    dst = open(os.path.join(destination_path,output_name+".txt"), "a")
    copyfile(template_file_path, dst.name)

    try:
        df = pd.read_csv(os.path.join(box_file), delimiter="\t", header= None)
    except pd.errors.EmptyDataError as e:
        print("skipped "+ file + ", it is empty")
        return

    df_numpy = df.to_numpy()
    
    
    for i in range(1, int(np.amax(df_numpy[:,4]))+1):
        df_np = df_numpy[df_numpy[:,4] == i, :]
        if(df_np.shape[0] <= 1):
            continue

        x = df_np[:,0]
        y = df_np[:,1]
        ID = df_np[:,4]

        # cumulative distance
        summation = get_cumulative_dist(x,y)
        
        # psi
        psi = calculatepsi(x,y)

        tilt = np.full(x.shape, 90)

        concat = np.concatenate([x[:, np.newaxis], y[:, np.newaxis],ID[:, np.newaxis], tilt[:, np.newaxis], psi[:, np.newaxis], summation[:, np.newaxis]], axis = 1)

        concat_list =(concat).tolist()

        
        output_string = list(map(write_line, concat_list))

        for line in output_string:
            dst.write(line)


def box_to_star_bulk(box_file_directory, output_name, template_file_path, destination_path):
    star_file_string = open(template_file_path, "r")
    dst = open(os.path.join(destination_path,output_name+".txt"), "a")
    copyfile(template_file_path, dst.name)
    size = 0
    for file in os.listdir((box_file_directory)):
        if (".box" in file):
            try:
                df = pd.read_csv(os.path.join(box_file_directory,file), delimiter="\t", header= None)
            except pd.errors.EmptyDataError as e:
                print("skipped "+ file + ", it is empty")
                continue
            print(file)
            df_numpy = df.to_numpy()
            
            
            for i in range(1, int(np.amax(df_numpy[:,4]))+1):
                df_np = df_numpy[df_numpy[:,4] == i, :]
                if(df_np.shape[0] <= 1):
                    continue

                x = df_np[:,0]
                y = df_np[:,1]
                ID = df_np[:,4]

                # cumulative distance
                summation = get_cumulative_dist(x,y)
                
                # psi
                psi = calculatepsi(x,y)

                tilt = np.full(x.shape, 90)

                concat = np.concatenate([x[:, np.newaxis], y[:, np.newaxis],ID[:, np.newaxis], tilt[:, np.newaxis], psi[:, np.newaxis], summation[:, np.newaxis]], axis = 1)

                concat_list =(concat).tolist()

                
                output_string = list(map(write_line, concat_list))

                for line in output_string:
                    dst.write(line)
            size += 1
    print("A total of "+ str(size)+ " files parsed.")
    dst.close()

